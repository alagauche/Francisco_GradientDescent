{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why would you use batch gradient descent vs stochastic gradient descent?\n",
    "# When do you know to use a particular optimization algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two questions are related, I'll answer both together.\n",
    "\n",
    "The long discussion is here:\n",
    "https://stats.stackexchange.com/questions/49528/batch-gradient-descent-versus-stochastic-gradient-descent\n",
    "\n",
    "This is a classic runtime vs optimality situation. Batch is more optimal at the cost of long run time for large datasets, and stochastic is quick and dirty.\n",
    "\n",
    "Thus, you will want to use batch if optimality is your primary concern, and stochastic if runtime is your concern. If you have a huge dataset and you are just exploring it, then maybe go with stochastic. If you are able to reduce or otherwise pre-process your dataset, then perhaps batch may become viable.\n",
    "\n",
    "A more technical discussion involves discussing how batch operates vs stochastic, specifically, with respect to the computation of the cost function. Batch is so costly because it processes every data point during each iteration of the cost function computation. The advantage is that batch guarantees it will converge to the global minimum for convex error surfaces and to a local minimum for non-convex surfaces. This optimality comes at the cost of high runtime.\n",
    "\n",
    "With stochastic, the gradient of the loss function is computed with a single random data point rather than the entire data set, as in batch. This is how stochastic immediately begins addressing the minimization. The disadvantages are that stochastic results in a larger variance of the loss function than batch, and also that it cannot guarantee global or local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is dependency injection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependency injection is an OOP concept. It helps answer some of the following questions:\n",
    "How can an application be independent of how its objects are created?\n",
    "How can a class be independent of how the objects it requires are created?\n",
    "How can the way objects are created be specified in separate configuration files?\n",
    "How can an application support different configurations?\n",
    "\n",
    "Dependency injection is the idea that you can decouple objects within a class such that the class's code doesn't have to be changed if any of the objects are changed or switched out. In other words, the class doesn't produce values within itself using \"static\" or \"new\" methods; all these values must be \"injected\" from outside the class by objects that are passed in.\n",
    "\n",
    "This "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the number of iterations it takes for each algorithm to obtain an estimate accurate to 1e-3 \n",
    "(you may wish to set a cap for maximum number of iterations). Which method converges to the optimal point in fewer iterations? Briefly explain why this result should be expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's look at batch descent, then stochastic, then answer the question afterwards. Precision will go to 0.001 in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy import stats \n",
    "from sklearn.datasets.samples_generator import make_regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent: -3.93, 81.67 4454\n",
      "Least Squares: -3.71, 82.90\n"
     ]
    }
   ],
   "source": [
    "# code from:\n",
    "# https://am207.github.io/2017/wiki/gradientdescent.html\n",
    "def gradient_descent(x, y, theta_init, step=0.001, maxsteps=0, precision=0.001, ):\n",
    "    costs = []\n",
    "    m = y.size # number of data points\n",
    "    theta = theta_init\n",
    "    history = [] # to store all thetas\n",
    "    preds = []\n",
    "    counter = 0\n",
    "    oldcost = 0\n",
    "    pred = np.dot(x, theta)\n",
    "    error = pred - y \n",
    "    currentcost = np.sum(error ** 2) / (2 * m)\n",
    "    preds.append(pred)\n",
    "    costs.append(currentcost)\n",
    "    history.append(theta)\n",
    "    counter+=1\n",
    "    while abs(currentcost - oldcost) > precision:\n",
    "        oldcost=currentcost\n",
    "        gradient = x.T.dot(error)/m \n",
    "        theta = theta - step * gradient  # update\n",
    "        history.append(theta)\n",
    "        \n",
    "        pred = np.dot(x, theta)\n",
    "        error = pred - y \n",
    "        currentcost = np.sum(error ** 2) / (2 * m)\n",
    "        costs.append(currentcost)\n",
    "        \n",
    "        if counter % 25 == 0: preds.append(pred)\n",
    "        counter+=1\n",
    "        if maxsteps:\n",
    "            if counter == maxsteps:\n",
    "                break\n",
    "        \n",
    "    return history, costs, preds, counter\n",
    "\n",
    "x, y = make_regression(n_samples = 100, \n",
    "                       n_features=1, \n",
    "                       n_informative=1, \n",
    "                       noise=20,\n",
    "                       random_state=2017)\n",
    "x = x.flatten()\n",
    "slope, intercept, _,_,_ = stats.linregress(x,y)\n",
    "best_fit = np.vectorize(lambda x: x * slope + intercept)\n",
    "\n",
    "xaug = np.c_[np.ones(x.shape[0]), x]\n",
    "theta_i = [-15, 40] + np.random.rand(2)\n",
    "history, cost, preds, iters = gradient_descent(xaug, y, theta_i, step=0.001)\n",
    "theta = history[-1]\n",
    "print(\"Gradient Descent: {:.2f}, {:.2f} {:d}\".format(theta[0], theta[1], iters))\n",
    "print(\"Least Squares: {:.2f}, {:.2f}\".format(intercept, slope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at stochastic descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-25.11218394,  -0.80995399]), array([ 1.        ,  0.03225343]), 11.534851890155354, -13.577332051876045, -25.1121839420314, 315.31089116920987)\n",
      "('start', 1, [315.31089116920987], 0)\n"
     ]
    }
   ],
   "source": [
    "def sgd(x, y, theta_init, step=0.001, maxsteps=0, precision=0.001, ):\n",
    "    costs = []\n",
    "    m = y.size # number of data points\n",
    "    oldtheta = 0\n",
    "    theta = theta_init\n",
    "    history = [] # to store all thetas\n",
    "    preds = []\n",
    "    grads=[]\n",
    "    counter = 0\n",
    "    oldcost = 0\n",
    "    epoch = 0\n",
    "    i = 0 #index\n",
    "    pred = np.dot(x[i,:], theta)\n",
    "    error = pred - y[i]\n",
    "    gradient = x[i,:].T*error\n",
    "    grads.append(gradient)\n",
    "    print(gradient,x[i],y[i],pred, error, np.sum(error ** 2) / 2)\n",
    "    currentcost = np.sum(error ** 2) / 2\n",
    "    counter+=1\n",
    "    preds.append(pred)\n",
    "    costsum = currentcost\n",
    "    costs.append(costsum/counter)\n",
    "    history.append(theta)\n",
    "    print(\"start\", counter, costs, oldcost)\n",
    "    while 1:\n",
    "        #while abs(costs[counter-1] - oldcost) > precision:\n",
    "        #while np.linalg.norm(theta - oldtheta) > precision:\n",
    "        #print(\"hi\", precision)\n",
    "        #oldcost=currentcost\n",
    "        gradient = x[i,:].T*error\n",
    "        grads.append(gradient)\n",
    "        oldtheta = theta\n",
    "        theta = theta - step * gradient  # update\n",
    "        history.append(theta)\n",
    "        i += 1\n",
    "        if i == m:#reached one past the end.\n",
    "            #break\n",
    "            epoch +=1\n",
    "            neworder = np.random.permutation(m)\n",
    "            x = x[neworder]\n",
    "            y = y[neworder]\n",
    "            i = 0\n",
    "        pred = np.dot(x[i,:], theta)\n",
    "        error = pred - y[i]\n",
    "        currentcost = np.sum(error ** 2) / 2\n",
    "        \n",
    "        #print(\"e/cc\",error, currentcost)\n",
    "        if counter % 25 == 0: preds.append(pred)\n",
    "        counter+=1\n",
    "        costsum += currentcost\n",
    "        oldcost = costs[counter-2]\n",
    "        costs.append(costsum/counter)\n",
    "        #print(counter, costs, oldcost)\n",
    "        if maxsteps:\n",
    "            #print(\"in maxsteps\")\n",
    "            if counter == maxsteps:\n",
    "                break\n",
    "        \n",
    "    return history, costs, preds, grads, counter, epoch\n",
    "\n",
    "history2, cost2, preds2, grads2, iters2, epoch2 = sgd(xaug, y, theta_i, maxsteps=5000, step=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER:\n",
    "For a precision of 0.001, it took batch 4454 iterations and stochastic only ~316. This is expected, because stochastic is quick and directly, getting to the answer much more quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the performance of stochastic gradient descent for the following learning rates: 1, 0.1, 0.001, 0.0001. \n",
    "Based on your observations, briefly describe the effect of the choice of learning rate on the performance of the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-25.11218394,  -0.80995399]), array([ 1.        ,  0.03225343]), 11.534851890155354, -13.577332051876045, -25.1121839420314, 315.31089116920987)\n",
      "('start', 1, [315.31089116920987], 0)\n",
      "(array([-25.11218394,  -0.80995399]), array([ 1.        ,  0.03225343]), 11.534851890155354, -13.577332051876045, -25.1121839420314, 315.31089116920987)\n",
      "('start', 1, [315.31089116920987], 0)\n",
      "(array([-25.11218394,  -0.80995399]), array([ 1.        ,  0.03225343]), 11.534851890155354, -13.577332051876045, -25.1121839420314, 315.31089116920987)\n",
      "('start', 1, [315.31089116920987], 0)\n",
      "(array([-25.11218394,  -0.80995399]), array([ 1.        ,  0.03225343]), 11.534851890155354, -13.577332051876045, -25.1121839420314, 315.31089116920987)\n",
      "('start', 1, [315.31089116920987], 0)\n"
     ]
    }
   ],
   "source": [
    "history2, cost2, preds2, grads2, iters2, epoch2 = sgd(xaug, y, theta_i, maxsteps=5000, step=1)\n",
    "history2, cost2, preds2, grads2, iters2, epoch2 = sgd(xaug, y, theta_i, maxsteps=5000, step=0.1)\n",
    "history2, cost2, preds2, grads2, iters2, epoch2 = sgd(xaug, y, theta_i, maxsteps=5000, step=0.001)\n",
    "history2, cost2, preds2, grads2, iters2, epoch2 = sgd(xaug, y, theta_i, maxsteps=5000, step=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER:\n",
    "It looks like changing the learning rate from 1 to 0.0001 doesn't seem to change any of the performance metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
